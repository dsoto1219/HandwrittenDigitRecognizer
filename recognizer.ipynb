{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a Jupyter notebook showing my progression in understanding 3Blue1Brown's [neural network series](https://www.youtube.com/watch?v=aircAruvnKk&list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi). I'm beginning by starting with the \"Hello World\" of neural networks, that being a network that can take in handwritten digits between 0 and 9 and tell you which digit it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with the usual imports\n",
    "import numpy as np\n",
    "from scipy.special import expit # sigmoid function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, I'm using the MNIST dataset, which contains over 50,000 different handwritten digits. The dataset comes from Michael Nielsen's [repository](https://github.com/mnielsen/neural-networks-and-deep-learning/tree/master/data) for his book on neural networks, [*Neural Networks and Deep Learning*](http://neuralnetworksanddeeplearning.com/) (free to read online).\n",
    "\n",
    "With this said, we of course start by loading the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Most of this code was from https://stackoverflow.com/a/25079162/18031673.\n",
    "I tweaked it a bit for formatting, and added the encoding bit myself. \n",
    "\"\"\"\n",
    "import gzip\n",
    "import pickle\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Load MNIST dataset\n",
    "with gzip.open('mnist.pkl.gz', 'rb') as f:\n",
    "    # This was likely encoded in Python2---to fix, using encoding 'latin1'\n",
    "    train_set, valid_set, test_set = pickle.load(f, encoding='latin1')\n",
    "# train_x: inputs (pictures of digits)\n",
    "# train_y: outputs (labels of digits)\n",
    "train_x, train_y = train_set\n",
    "\n",
    "\n",
    "# Show an example image (the first image in the training dataset)\n",
    "plt.imshow(train_x[0].reshape((28, 28)), cmap=cm.Greys_r)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the dataset loaded, we can begin constructing the neural network. I use the following list of constant integers to represent the network's dimensions (which are, at this point, identical to the ones shown in 3Blue1Brown's video.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the same shape as in 3Blue1Brown's Video\n",
    "LAYER_HEIGHTS = [\n",
    "    train_x.shape[1], # 784\n",
    "    16,\n",
    "    16,\n",
    "    10, # Number of digits in base 10\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then initialize the weight matrices, which we organize in a larger array that I name `weights`. Although there are 4 layers in the network, we need 3 weight matrices so that each pair of layers has their own weight matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array([[-0.50183952,  1.80285723,  0.92797577, ...,  0.17089777,\n",
       "               -0.99280376, -0.61721603],\n",
       "              [-1.27360913,  1.63380225,  0.33356718, ..., -0.30504699,\n",
       "                0.6701996 , -1.61785874],\n",
       "              [ 0.4954373 , -0.19292929,  0.34643385, ..., -1.95947526,\n",
       "                0.54438419,  1.65314779],\n",
       "              ...,\n",
       "              [-1.92571712,  1.55457068, -1.09239693, ...,  0.67344281,\n",
       "                0.96059757, -0.2074852 ],\n",
       "              [ 1.75010395,  0.94662694, -0.16830168, ...,  1.35648641,\n",
       "                1.63887325,  0.036981  ],\n",
       "              [ 0.77709899, -1.55279852,  0.26115584, ..., -0.29539381,\n",
       "                1.78337764, -1.12908386]])                             ,\n",
       "       array([[-0.97303359, -1.59644479,  0.4222811 ,  0.7194915 ,  0.57172483,\n",
       "                1.44452097, -0.05429666, -1.46217184, -0.84237948,  0.64971989,\n",
       "                0.45248789,  0.12401252,  0.73185767,  0.5495634 ,  1.52529956,\n",
       "                0.34406551],\n",
       "              [ 1.11440543, -1.00517138,  0.71273034,  1.60877647, -0.45707069,\n",
       "                1.11641675,  0.8991572 , -1.76189521,  0.32603324, -1.4792426 ,\n",
       "                1.86927669,  1.24563001, -1.5611048 , -1.51299201,  0.37789542,\n",
       "               -0.6204433 ],\n",
       "              [-1.86037656,  0.16656603, -0.4486196 , -1.59569403,  1.20768157,\n",
       "                1.66030706,  1.02637574,  1.28968924, -1.13403773, -0.9457082 ,\n",
       "               -1.16588984,  1.06025373,  1.79166832,  0.86734883,  1.52586706,\n",
       "                0.55479638],\n",
       "              [-0.4493604 , -0.29695354, -1.69871427, -1.87417122,  0.78190242,\n",
       "               -0.24628443,  0.20886027,  0.23064499, -0.89049675, -0.09642996,\n",
       "               -0.11695911, -0.44629112,  1.28270153, -0.19534399,  0.4145781 ,\n",
       "                1.58208048],\n",
       "              [ 1.46493449,  1.56168882, -0.91998001, -1.86007005, -0.9557328 ,\n",
       "               -0.88517062,  1.63744131,  0.59697093, -1.67318416, -1.45848562,\n",
       "               -1.3772955 ,  0.52168699,  0.9416561 ,  1.43857564,  1.7625462 ,\n",
       "               -1.19318177],\n",
       "              [-0.76091006, -1.03870848, -0.56495373,  1.65866043,  0.30045027,\n",
       "                0.95276759, -0.03952306, -1.88456835, -1.74321806,  0.15169213,\n",
       "                0.87515614, -1.13867789,  0.8876383 ,  1.24266309, -0.35241009,\n",
       "                0.98567693],\n",
       "              [-0.3838802 ,  0.71340252,  1.0559882 ,  1.96770647, -0.61841335,\n",
       "               -0.35583688, -1.33751976, -1.18370777,  0.77358001,  1.66818236,\n",
       "               -0.42158019, -1.28062221, -0.859602  , -0.17979318, -0.83739868,\n",
       "               -1.06568367],\n",
       "              [ 0.94393796, -1.96862032,  0.15692211,  1.17506723, -0.93508685,\n",
       "                0.41316604,  0.67560042,  0.62009879, -0.21660146, -0.61368805,\n",
       "                1.34369629,  1.03378383, -0.71497931, -1.58792322, -1.71276982,\n",
       "               -1.62289609],\n",
       "              [ 0.33147744, -1.7933513 , -0.6522925 ,  1.01279881, -0.82260733,\n",
       "                1.05323231,  0.98186815, -1.01669147,  0.91528872,  0.99110655,\n",
       "               -0.4101843 , -1.15831807,  0.08508323,  1.68559035,  0.55846693,\n",
       "               -1.30831001],\n",
       "              [ 0.7310277 , -0.29118789,  0.36611519,  0.93625614,  0.05978941,\n",
       "                1.2559359 ,  0.88862232,  0.46029336, -1.39682874,  1.34379644,\n",
       "                1.74362234, -1.4521395 , -0.04703548, -0.96444503,  1.01809323,\n",
       "                0.88651854],\n",
       "              [-1.43645952,  1.50810909, -1.27610774,  1.1890361 , -0.17207856,\n",
       "               -0.68691083, -1.36704295, -1.32954298,  0.64756222,  0.20172155,\n",
       "               -1.51165831, -1.54920856, -1.7107577 ,  0.97506939,  0.84752834,\n",
       "               -1.76627604],\n",
       "              [ 0.2410803 , -1.66129538,  1.61498308,  1.62846968,  0.79293196,\n",
       "                1.70475569,  1.24581212,  1.3141543 ,  0.2788314 , -0.77576321,\n",
       "               -1.12880354, -0.69119991,  0.51398172, -1.30937386, -0.96543905,\n",
       "               -0.12775655],\n",
       "              [-1.06779961,  0.35457468,  1.69270411,  0.99235746,  0.66570646,\n",
       "                0.3308859 , -0.04820836, -1.25374456,  1.57884182, -1.00585599,\n",
       "               -1.63476449,  1.00006072, -1.29753786, -0.512416  , -1.88686029,\n",
       "               -1.45172823],\n",
       "              [-1.30718548, -1.78235949,  0.62662783,  1.34803118, -0.50673837,\n",
       "                1.49830591, -1.1466137 , -0.69843831, -1.39705203,  0.48223678,\n",
       "               -0.32052164,  0.45313339,  1.04669962,  0.18281206,  0.51052142,\n",
       "                1.74100126],\n",
       "              [-0.80374276, -0.56334425,  0.87081345,  0.44522207, -1.28586838,\n",
       "               -0.49541076, -0.12864795, -0.32244065, -1.28690077,  1.69772037,\n",
       "                1.04927505, -0.07457667,  0.72024411,  1.58913069, -1.45530343,\n",
       "               -0.9985078 ],\n",
       "              [ 0.17080499,  1.19604149, -1.85498042,  1.9360726 , -0.18037359,\n",
       "               -0.56307544, -0.82910225, -1.30257317,  1.16629564,  1.82165666,\n",
       "               -0.34542098,  1.80968278,  1.29519046, -0.07579549,  0.69610472,\n",
       "               -0.26006328]])                                                  ,\n",
       "       array([[ 2.34893633e-01, -1.76781465e+00,  7.85053901e-01,\n",
       "               -1.78870142e+00,  1.26833979e+00,  1.29978772e+00,\n",
       "               -1.05169085e+00, -7.05348876e-01, -7.47584858e-02,\n",
       "                3.86651628e-01, -8.50585353e-01,  3.69945619e-01,\n",
       "               -8.08851707e-01, -1.77803712e+00, -1.98988980e+00,\n",
       "               -1.59539577e+00],\n",
       "              [ 1.16900280e+00,  1.84572525e+00, -2.92135203e-01,\n",
       "                5.07358138e-02, -1.41260732e+00,  2.04125411e-01,\n",
       "               -1.42138039e+00,  4.44857325e-01,  1.73303467e+00,\n",
       "               -1.21720584e+00,  1.05825487e+00, -1.90599031e+00,\n",
       "               -4.98011035e-01, -1.55700597e+00, -5.90098234e-01,\n",
       "               -1.30585232e+00],\n",
       "              [-5.06780040e-01, -3.29908776e-01, -7.97635509e-01,\n",
       "                6.26487798e-01,  1.67540821e+00, -3.97618504e-01,\n",
       "               -1.23062737e+00, -9.17108967e-01,  1.41600329e+00,\n",
       "                2.86558893e-01, -1.79955871e-01, -1.40145311e+00,\n",
       "               -2.01090767e-01, -8.86031987e-01,  1.77265251e+00,\n",
       "                1.53628044e+00],\n",
       "              [-1.66438983e+00,  6.66139570e-02, -1.09976662e+00,\n",
       "               -3.56891642e-01,  1.50739199e+00,  1.10058080e-01,\n",
       "               -6.63138827e-01, -1.16844658e+00,  1.20129944e+00,\n",
       "                4.98072061e-01, -1.27738158e-01, -1.13006258e+00,\n",
       "               -6.63014503e-01,  1.83937371e+00,  8.03597504e-02,\n",
       "               -3.97202875e-01],\n",
       "              [ 8.56881694e-02,  1.11595402e+00, -6.39564254e-01,\n",
       "               -1.28517552e+00,  3.39744473e-01,  6.60816414e-01,\n",
       "                8.50872012e-01,  1.52795036e+00, -5.15303517e-01,\n",
       "               -1.69858042e+00,  1.83339433e+00, -2.59952290e-01,\n",
       "                4.93030039e-01,  6.65221293e-01,  1.86054835e-01,\n",
       "               -1.17896988e+00],\n",
       "              [ 1.02057220e+00,  1.21500790e+00,  2.11902344e-01,\n",
       "               -4.57553577e-02, -1.54424727e+00, -1.66419335e+00,\n",
       "               -6.41740618e-01, -7.56615378e-01,  1.81462580e+00,\n",
       "                1.13449097e+00,  6.39697181e-01,  7.05923561e-02,\n",
       "               -1.33052988e+00,  1.91382669e+00, -4.99837207e-01,\n",
       "               -1.57229759e+00],\n",
       "              [-2.48044171e-02,  1.49599205e+00,  1.54916401e+00,\n",
       "               -1.95613634e+00,  1.54518298e+00, -9.14063130e-01,\n",
       "               -1.84411054e+00,  1.39116108e+00,  1.45546702e+00,\n",
       "                3.84924319e-01,  2.97735029e-01,  1.25248109e+00,\n",
       "                1.14523821e+00,  1.56042189e+00,  2.10989790e-01,\n",
       "                1.87058837e+00],\n",
       "              [ 1.98458732e+00, -1.53382156e+00,  1.39817504e+00,\n",
       "               -7.10969006e-04, -4.49734647e-01,  4.52289240e-01,\n",
       "               -1.77613777e+00,  2.58444751e-02,  1.48356228e+00,\n",
       "               -1.14615394e+00, -2.94440421e-01,  1.75792355e+00,\n",
       "               -2.85744649e-01, -5.66529471e-01, -2.37853408e-01,\n",
       "                7.78110661e-02],\n",
       "              [ 5.27965377e-01,  1.20277120e+00, -1.91591177e-01,\n",
       "                1.26992374e+00,  1.34882645e-01, -6.46077959e-01,\n",
       "                6.31803312e-01,  8.70889019e-01,  2.32195903e-01,\n",
       "               -1.77354011e+00, -1.32046850e+00, -8.58809116e-01,\n",
       "               -8.69497576e-01,  6.93683201e-01, -1.92660535e+00,\n",
       "                1.02272711e+00],\n",
       "              [-9.38630101e-01, -7.59912615e-01,  1.11639312e-01,\n",
       "               -1.13629760e+00,  1.53788525e+00, -1.65852488e+00,\n",
       "               -2.22470551e-01,  1.39768908e+00,  4.63375578e-01,\n",
       "               -8.30681937e-01, -3.16959169e-01,  8.26777521e-01,\n",
       "                1.89304297e+00,  1.57255487e+00, -6.30268766e-01,\n",
       "                1.99279152e+00]])                                ],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize random -list of weight matrices\n",
    "weights = np.empty(len(LAYER_HEIGHTS) - 1, dtype=object)\n",
    "\n",
    "np.random.seed(42)\n",
    "for i in range(1, len(weights)+1):\n",
    "    weights[i-1] = np.random.uniform(-2, 2, (LAYER_HEIGHTS[i], LAYER_HEIGHTS[i-1]))\n",
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similiarly, we organize an array containing 3 bias vectors, one for each pair of layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array([-1.98598135, -1.88948098,  1.29536206, -1.20214925, -1.75692293,\n",
       "              -1.05140771, -0.29559938,  0.92226508,  0.49734211, -1.04951513,\n",
       "               0.01308179,  1.70485642,  1.26003111, -0.70724086,  1.92905825,\n",
       "               0.8344816 ])                                                   ,\n",
       "       array([-1.75020258, -1.85935715, -1.3263682 ,  0.91142347, -1.2650443 ,\n",
       "               0.04594708, -1.62695952,  1.68354463, -0.62415755,  1.63252823,\n",
       "               1.77950257, -1.97548541, -0.14345925, -1.90137578,  1.63477107,\n",
       "               0.07363018])                                                   ,\n",
       "       array([-1.70022395, -1.55889309, -0.4659639 ,  1.76093677,  0.77163661,\n",
       "               1.47047546, -0.53417341, -1.8271452 ,  1.89727055, -1.93130804])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random biases\n",
    "biases = np.empty(len(LAYER_HEIGHTS) - 1, dtype=object)\n",
    "for i in range(len(biases)):\n",
    "    biases[i] = np.random.uniform(-2, 2, LAYER_HEIGHTS[i+1])\n",
    "biases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our activations for the first layer will be the \"flatted\" array of grayscale pixel values that represent a white digit drawn onto a black board. Let's start with a test run with a single arbitrarily chosen digit and see how well the network does with our randomly initialized weights and biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_index = 10000 # chose this index because I liked the way the number looked\n",
    "activations = np.empty(len(LAYER_HEIGHTS), dtype=object) # empty activations array to contain activations for all layers\n",
    "\n",
    "activations[0] = train_x[test_index]\n",
    "plt.imshow(activations[0].reshape((28, 28)), cmap=cm.Greys_r)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We calculate each layer's activation vector using the formula\n",
    "$$\n",
    "\\mathbf{a}^{(i)} = \\sigma\\left(\\mathbf{W}_{i-1}\\mathbf{a}^{(i-1)} + \\mathbf{b}_{i-1}\\right)\n",
    "$$\n",
    "Where $\\mathbf{a}^{(i)}$ is the activation vector, $\\mathbf{W}_{i-1}$ is the weight matrix, and $\\mathbf{b}_{i-1}$ is the bias vector, each indexed based on which layer they correspond to, for $i \\in \\{1, 2, 3\\}$. Moreover, $\\sigma$ is the sigmoid function. Although 3Blue1Brown mentioned that the ReLU function tends to be a better activation function, I want to stick to the sigmoid function for now since it seems like that's what he used in the video. Plus, I prefer the sigmoid function's output for now, since tells us the network's level of confidence with its answer, which I personally like.\n",
    "\n",
    "Continuing, we implement each activation vector's calculation as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array([9.33231892e-01, 9.99625620e-01, 9.21778290e-03, 9.97926584e-01,\n",
       "              9.99738418e-01, 9.98369802e-01, 9.99565148e-01, 1.39248314e-01,\n",
       "              4.57126727e-02, 4.38513258e-06, 4.20900529e-05, 8.25153688e-01,\n",
       "              8.92942470e-04, 9.96614620e-01, 9.09691699e-01, 2.05859928e-02]),\n",
       "       array([0.55736516, 0.72381646, 0.93501558, 0.24846419, 0.9546275 ,\n",
       "              0.69358096, 0.02277593, 0.4202985 , 0.77087925, 0.98108154,\n",
       "              0.76277771, 0.35634925, 0.40917132, 0.05664381, 0.25729164,\n",
       "              0.9756615 ])                                               ,\n",
       "       array([0.03038738, 0.0884819 , 0.86890401, 0.76028722, 0.63023341,\n",
       "              0.74474981, 0.99944194, 0.40550893, 0.63899321, 0.4896489 ])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(1, len(activations)):\n",
    "    activations[i] = expit(weights[i-1] @ activations[i-1] + biases[i-1])\n",
    "# Not showing the first layer's activations, since we technically already saw it because of the image before\n",
    "activations[1:] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we focus our attention on the last array, we see this network performed pretty poorly. Although it did tell us we are looking at a 3 with around 76% confidence, it also told us that we were looking at a 6 with 99.9% confidence. So, as expected when using random weights and biases, this did not do well. If we continue by looking at the cost function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(3.5844453233337132)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_digit = train_y[test_index]\n",
    "label = np.zeros(LAYER_HEIGHTS[-1])\n",
    "label[correct_digit] = 1\n",
    "print(label)\n",
    "\n",
    "# Cost\n",
    "sum((activations[-1] - label)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that our cost is pretty high."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us proceed by using these same random weights and biases, and find the average cost across all 50,000 entries of our training data. This will amount to doing exactly what we did before, only in a larger `for` loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 784)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [00:02<00:00, 20145.60it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "print(train_x.shape)\n",
    "\n",
    "costs = np.zeros(train_x.shape[0]) # storing all individual costs here\n",
    "\n",
    "for i in tqdm(range(len(costs))):\n",
    "    activations = np.empty(len(LAYER_HEIGHTS), dtype=object)\n",
    "    # Feed-Forward\n",
    "    activations[0] = train_x[i]\n",
    "    for j in range(1, len(activations)):\n",
    "        activations[j] = expit(weights[j-1] @ activations[j-1] + biases[j-1])\n",
    "    \n",
    "    # Create \"correct final layer\"\n",
    "    correct_digit = train_y[i]\n",
    "    label = np.zeros(LAYER_HEIGHTS[-1])\n",
    "    label[correct_digit] = 1\n",
    "\n",
    "    # Cost for this prediction\n",
    "    costs[i] = sum((activations[-1] - label)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(3.550455196767095)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total cost\n",
    "costs.mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "digit_recognizer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
